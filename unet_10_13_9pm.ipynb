{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet_10-13_9pm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/roman807/TGS_Salt/blob/master/unet_10_13_9pm.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "f5Dnee-bbRvx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Unet: train model and evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "LepinJ_1bZdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa0f15fc-0e22-4e1c-a26d-b5f64bd774a5"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import confusion_matrix, log_loss\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "import h5py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hbj53MyPbcpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "9f57f6a3-e190-4b8c-9577-040d7a958803"
      },
      "cell_type": "code",
      "source": [
        "##### Use kaggle API\n",
        "!pip install kaggle\n",
        "api_token = {\"username\":\"romanm87\",\"key\":\"daa9da19c31bf091978760ad6eb373f3\"}\n",
        "os.chdir('/')\n",
        "!mkdir ~/.kaggle #kaggle API searches in root directory for .kaggle/kaggle.json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "# API link from Kaggle:\n",
        "!kaggle competitions download -c tgs-salt-identification-challenge\n",
        "zip_ref = zipfile.ZipFile('train.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/78/832b9a9ec6b3baf8ec566e1f0a695f2fd08d2c94a6797257a106304bfc3c/kaggle-1.4.7.1.tar.gz (52kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.8.24)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.26.0)\n",
            "Collecting python-slugify (from kaggle)\n",
            "  Downloading https://files.pythonhosted.org/packages/00/ad/c778a6df614b6217c30fe80045b365bfa08b5dd3cb02e8b37a6d25126781/python-slugify-1.2.6.tar.gz\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Collecting Unidecode>=0.04.16 (from python-slugify->kaggle)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/ef/67085e30e8bbcdd76e2f0a4ad8151c13a2c5bce77c85f8cad6e1f16fb141/Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n",
            "\u001b[K    100% |████████████████████████████████| 235kB 5.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
            "  Running setup.py bdist_wheel for kaggle ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/44/2c/df/22a6eeb780c36c28190faef6252b739fdc47145fd87a6642d4\n",
            "  Running setup.py bdist_wheel for python-slugify ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e3/65/da/2045deea3098ed7471eca0e2460cfbd3fdfe8c1d6fa6fcac92\n",
            "Successfully built kaggle python-slugify\n",
            "Installing collected packages: Unidecode, python-slugify, kaggle\n",
            "Successfully installed Unidecode-1.0.22 kaggle-1.4.7.1 python-slugify-1.2.6\n",
            "Downloading depths.csv to /\n",
            "  0% 0.00/322k [00:00<?, ?B/s]\n",
            "100% 322k/322k [00:00<00:00, 60.9MB/s]\n",
            "Downloading sample_submission.csv to /\n",
            "  0% 0.00/264k [00:00<?, ?B/s]\n",
            "100% 264k/264k [00:00<00:00, 76.5MB/s]\n",
            "Downloading train.csv to /\n",
            "  0% 0.00/922k [00:00<?, ?B/s]\n",
            "100% 922k/922k [00:00<00:00, 61.1MB/s]\n",
            "Downloading test.zip to /\n",
            " 93% 152M/163M [00:01<00:00, 111MB/s] \n",
            "100% 163M/163M [00:01<00:00, 111MB/s]\n",
            "Downloading train.zip to /\n",
            " 45% 17.0M/37.9M [00:00<00:00, 69.0MB/s]\n",
            "100% 37.9M/37.9M [00:00<00:00, 132MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5ENokPHZbhQw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Prepare data\n",
        "tr_image_dir = os.chdir('/images')\n",
        "train_im = os.listdir(tr_image_dir)\n",
        "x = np.array([np.array(cv2.imread(p, cv2.IMREAD_GRAYSCALE)) for p in train_im]) / 255\n",
        "tr_masks_dir = os.chdir('/masks')\n",
        "train_ma = os.listdir(tr_masks_dir)\n",
        "y = np.array([np.array(cv2.imread(p, cv2.IMREAD_GRAYSCALE)) for p in train_ma]) / 255\n",
        "# expand dimensions for CNN\n",
        "x = np.expand_dims(x, axis=3)\n",
        "y = np.expand_dims(y, axis=3)\n",
        "# split training vs validation set\n",
        "train_val_split = 0.1\n",
        "x_train = x[0:int(x.shape[0]*(1-train_val_split)),:,:,:]\n",
        "y_train = y[0:int(y.shape[0]*(1-train_val_split)),:,:,:]\n",
        "x_val = x[int(x.shape[0]*(1-train_val_split)):,:,:,:]\n",
        "y_val = y[int(y.shape[0]*(1-train_val_split)):,:,:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VM_PQxiLbqpH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### define model\n",
        "\n",
        "def unet(pretrained_weights = None, input_size=(101,101,1)):\n",
        "    inputs = Input(input_size)\n",
        "    input_padded = ZeroPadding2D(padding=((14, 13), (14, 13)))(inputs)  ## use zero padding to match dims after maxpool/upsample\n",
        "    conv1 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(input_padded)\n",
        "    conv1 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    conv1 = Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    conv1 = Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2), border_mode=\"same\")(conv1)\n",
        "    conv2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    conv2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    conv2 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    conv2 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2), border_mode=\"same\")(conv2)\n",
        "    conv3 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    conv3 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    conv3 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    conv3 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2), border_mode=\"same\")(conv3)\n",
        "    conv4 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "    conv4 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    conv4 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    conv4 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2), border_mode=\"same\")(conv4)#(drop4)\n",
        "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "    conv5 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "    conv5 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "    \n",
        "    pool5 = MaxPooling2D(pool_size=(2, 2), border_mode=\"same\")(conv5)\n",
        "    conv5b = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool5)\n",
        "    conv5b = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5b)\n",
        "    conv5b = Conv2D(1024, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv5b)\n",
        "    conv5b = Conv2D(1024, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv5b)\n",
        "    up5b = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv5b))\n",
        "    merge6 = merge([conv5,up5b], mode='concat', concat_axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "    \n",
        "    up6 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv5))\n",
        "    merge6 = merge([conv4,up6], mode='concat', concat_axis = 3)\n",
        "    conv6 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "    conv6 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "    conv6 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "    conv6 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "    up7 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv6))\n",
        "    merge7 = merge([conv3,up7], mode='concat', concat_axis = 3)\n",
        "    conv7 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "    conv7 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "    conv7 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "    conv7 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "    up8 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = merge([conv2,up8], mode='concat', concat_axis=3)\n",
        "    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "    up9 = Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = merge([conv1,up9], mode='concat', concat_axis=3)\n",
        "    conv9 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "    conv9 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv9 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "    crop = Cropping2D(cropping=((14, 13), (14, 13)))(conv10)\n",
        "    model = Model(inputs=inputs, output=crop)\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "    return model\n",
        "  \n",
        "# def unet(pretrained_weights = None, input_size=(101,101,1), ks=kernel_size):\n",
        "#     inputs = Input(input_size)\n",
        "#     input_padded = ZeroPadding2D(padding=((14, 13), (14, 13)))(inputs)  ## use zero padding to match dims after maxpool/upsample\n",
        "#     conv1 = Conv2D(64, 4, activation='relu', padding='same', kernel_initializer='he_normal')(input_padded)\n",
        "#     conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "#     conv1 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "#     pool1 = MaxPooling2D(pool_size=(2, 2), border_mode=\"same\")(conv1)\n",
        "#     conv2 = Conv2D(128, 4, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "#     conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "#     conv2 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "#     pool2 = MaxPooling2D(pool_size=(2, 2), border_mode=\"same\")(conv2)\n",
        "#     conv3 = Conv2D(256, 4, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "#     conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "#     conv3 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "#     pool3 = MaxPooling2D(pool_size=(2, 2), border_mode=\"same\")(conv3)\n",
        "#     conv4 = Conv2D(512, 4, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "#     conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "#     conv4 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "#     pool4 = MaxPooling2D(pool_size=(2, 2), border_mode=\"same\")(conv4)#(drop4)\n",
        "#     conv5 = Conv2D(1024, 4, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "#     conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "#     conv5 = Conv2D(1024, 2, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "#     up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv5))\n",
        "#     merge6 = merge([conv4,up6], mode='concat', concat_axis = 3)\n",
        "#     conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "#     conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "#     conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "#     up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv6))\n",
        "#     merge7 = merge([conv3,up7], mode='concat', concat_axis = 3)\n",
        "#     conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "#     conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "#     conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "#     up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "#     merge8 = merge([conv2,up8], mode='concat', concat_axis=3)\n",
        "#     conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "#     conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "#     conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "#     up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "#     merge9 = merge([conv1,up9], mode='concat', concat_axis=3)\n",
        "#     conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "#     conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "#     conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "#     conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "#     crop = Cropping2D(cropping=((14, 13), (14, 13)))(conv10)\n",
        "#     model = Model(inputs=inputs, output=crop)\n",
        "#     if(pretrained_weights):\n",
        "#     \tmodel.load_weights(pretrained_weights)\n",
        "#     return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NcCHRAf0b2br",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Define evaluation metrics [NOT IN USE]\n",
        "# class MeanIoU(object):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#     def mean_iou(self, y_true, y_pred):\n",
        "#         # Wraps np_mean_iou method and uses it as a TensorFlow op.\n",
        "#         # Takes numpy arrays as its arguments and returns numpy arrays as outputs\n",
        "#         return tf.py_func(self.np_mean_iou, [y_true, y_pred], tf.float64)\n",
        "#     def np_mean_iou(self, y_true, y_pred):\n",
        "#         y_pred = np.round(y_pred + 0.05, 0).reshape(-1)\n",
        "#         y_true = y_true.reshape(-1)        \n",
        "#         conf = confusion_matrix(y_pred, y_true)        \n",
        "#         # Compute the IoU and mean IoU from the confusion matrix:\n",
        "#         true_positive = conf[1,1]\n",
        "#         false_positive = conf[1,0]\n",
        "#         false_negative = conf[0,1]\n",
        "#         # Just in case we get a division by 0, ignore/hide the error and set the value to 0\n",
        "#         with np.errstate(divide='ignore', invalid='ignore'):\n",
        "#             iou = true_positive / (true_positive + false_positive + false_negative)\n",
        "#         #iou[np.isnan(iou)] = 0\n",
        "#         return np.mean(iou).astype(np.float64)\n",
        "# miou = MeanIoU()\n",
        "# def bin_acc05(y_true, y_pred):\n",
        "#     return K.mean(K.equal(y_true, K.round(y_pred + 0.05)), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X3Vn5GGTcHX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2434
        },
        "outputId": "f59396ef-a7da-4c31-8e8d-370229882ffd"
      },
      "cell_type": "code",
      "source": [
        "##### Define model \n",
        "\n",
        "# # sgd (decay learning rate by 10 over all training steps)\n",
        "# n_epochs = 20\n",
        "# batch_size = 100\n",
        "# n_steps = (3600 / batch_size) * n_epochs\n",
        "# total_decay = 0.001\n",
        "# decay = 1 - total_decay ** (1 / n_steps)\n",
        "\n",
        "model = unet()\n",
        "adam = optimizers.Adam(lr = 1e-4)   # best run 1e-4 // defaul: 1e-3\n",
        "#sgd = optimizers.SGD(lr=0.1, momentum=0.99, decay=decay, nesterov=False)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "  name=name)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:61: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"cr...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 128, 128, 1)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 32) 320         zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 128, 128, 32) 9248        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 32) 4128        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 32) 4128        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 64)   36928       conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 64)   16448       conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 64)   16448       conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 128)  65664       conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 128)  65664       conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 256)  262400      conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 256)  262400      conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 256)    0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 512)    1180160     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 512)    1049088     conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 512)    1049088     conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 16, 16, 512)  0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 256)  524544      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "merge_2 (Merge)                 (None, 16, 16, 512)  0           conv2d_16[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 256)  1179904     merge_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 256)  0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 32, 32, 128)  131200      up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "merge_3 (Merge)                 (None, 32, 32, 256)  0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 32, 32, 128)  295040      merge_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 128)  0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 64, 64, 64)   32832       up_sampling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "merge_4 (Merge)                 (None, 64, 64, 128)  0           conv2d_8[0][0]                   \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 64, 64, 64)   73792       merge_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 128, 128, 32) 8224        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "merge_5 (Merge)                 (None, 128, 128, 64) 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 128, 128, 32) 18464       merge_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 128, 128, 2)  578         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 128, 128, 1)  3           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "cropping2d_1 (Cropping2D)       (None, 101, 101, 1)  0           conv2d_50[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 12,113,957\n",
            "Trainable params: 12,113,957\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-COan7NJcRnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1788
        },
        "outputId": "fdc2f393-1cf2-47ce-fc1e-b282ca944440"
      },
      "cell_type": "code",
      "source": [
        "##### Run model\n",
        "filepath = 'weights.best.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model.fit(x_train, y_train, epochs=25, batch_size=64, validation_data=(x_val,y_val), callbacks=callbacks_list, verbose=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3600 samples, validate on 400 samples\n",
            "Epoch 1/25\n",
            "3600/3600 [==============================] - 89s 25ms/step - loss: 0.5945 - acc: 0.7508 - val_loss: 0.5354 - val_acc: 0.7628\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.76284, saving model to weights.best.hdf5\n",
            "Epoch 2/25\n",
            "3600/3600 [==============================] - 74s 20ms/step - loss: 0.5226 - acc: 0.7508 - val_loss: 0.4989 - val_acc: 0.7628\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.76284\n",
            "Epoch 3/25\n",
            "3600/3600 [==============================] - 74s 20ms/step - loss: 0.4334 - acc: 0.7693 - val_loss: 0.3664 - val_acc: 0.8557\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.76284 to 0.85567, saving model to weights.best.hdf5\n",
            "Epoch 4/25\n",
            "3600/3600 [==============================] - 74s 20ms/step - loss: 0.3705 - acc: 0.8551 - val_loss: 0.3210 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.85567 to 0.87884, saving model to weights.best.hdf5\n",
            "Epoch 5/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.3188 - acc: 0.8768 - val_loss: 0.3022 - val_acc: 0.8907\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.87884 to 0.89071, saving model to weights.best.hdf5\n",
            "Epoch 6/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.2905 - acc: 0.8895 - val_loss: 0.2632 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.89071 to 0.90622, saving model to weights.best.hdf5\n",
            "Epoch 7/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.2777 - acc: 0.8934 - val_loss: 0.2608 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.90622\n",
            "Epoch 8/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.2834 - acc: 0.8935 - val_loss: 0.2413 - val_acc: 0.9130\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.90622 to 0.91296, saving model to weights.best.hdf5\n",
            "Epoch 9/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.2496 - acc: 0.9057 - val_loss: 0.2366 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.91296 to 0.91421, saving model to weights.best.hdf5\n",
            "Epoch 10/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.2315 - acc: 0.9136 - val_loss: 0.2330 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.91421 to 0.91820, saving model to weights.best.hdf5\n",
            "Epoch 11/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.2279 - acc: 0.9137 - val_loss: 0.2524 - val_acc: 0.9034\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.91820\n",
            "Epoch 12/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.2189 - acc: 0.9186 - val_loss: 0.2431 - val_acc: 0.9220\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.91820 to 0.92196, saving model to weights.best.hdf5\n",
            "Epoch 13/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.2333 - acc: 0.9162 - val_loss: 0.2298 - val_acc: 0.9131\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.92196\n",
            "Epoch 14/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.2183 - acc: 0.9207 - val_loss: 0.2106 - val_acc: 0.9290\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.92196 to 0.92899, saving model to weights.best.hdf5\n",
            "Epoch 15/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1921 - acc: 0.9278 - val_loss: 0.1832 - val_acc: 0.9326\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.92899 to 0.93264, saving model to weights.best.hdf5\n",
            "Epoch 16/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1772 - acc: 0.9339 - val_loss: 0.2012 - val_acc: 0.9279\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.93264\n",
            "Epoch 17/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1785 - acc: 0.9337 - val_loss: 0.1938 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.93264\n",
            "Epoch 18/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1731 - acc: 0.9342 - val_loss: 0.1986 - val_acc: 0.9274\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.93264\n",
            "Epoch 19/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1638 - acc: 0.9387 - val_loss: 0.2001 - val_acc: 0.9282\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.93264\n",
            "Epoch 20/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1624 - acc: 0.9392 - val_loss: 0.2000 - val_acc: 0.9164\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.93264\n",
            "Epoch 21/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1506 - acc: 0.9429 - val_loss: 0.1978 - val_acc: 0.9318\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.93264\n",
            "Epoch 22/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1411 - acc: 0.9462 - val_loss: 0.1900 - val_acc: 0.9302\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.93264\n",
            "Epoch 23/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1809 - acc: 0.9324 - val_loss: 0.2732 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.93264\n",
            "Epoch 24/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1898 - acc: 0.9266 - val_loss: 0.2050 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.93264\n",
            "Epoch 25/25\n",
            "3600/3600 [==============================] - 74s 21ms/step - loss: 0.1460 - acc: 0.9451 - val_loss: 0.1985 - val_acc: 0.9386\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.93264 to 0.93858, saving model to weights.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8ccaa96898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "FozQAleLOOb5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### load best weights:\n",
        "\n",
        "model.load_weights('weights.best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62UOKlRJcSWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "aafcbf21-45bc-4992-ee76-f1ec48ed0965"
      },
      "cell_type": "code",
      "source": [
        "##### Predict results\n",
        "y_train_pred = model.predict(x_train, verbose=1)\n",
        "y_val_pred = model.predict(x_val, verbose=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3600/3600 [==============================] - 27s 8ms/step\n",
            "400/400 [==============================] - 3s 7ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vxyAvf7Dgc14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(y_val_pred.min())\n",
        "print(y_val_pred.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9cxpGL-cnCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "2c175187-66b8-4a6a-89ae-1bfdf657000f"
      },
      "cell_type": "code",
      "source": [
        "### Evaluate results:\n",
        "y_train = y_train.reshape(-1)[:(400*101*101)]\n",
        "y_train_pred = y_train_pred.reshape(-1)[:(400*101*101)]\n",
        "y_val = y_val.reshape(-1)\n",
        "y_val_pred = y_val_pred.reshape(-1)\n",
        "\n",
        "true_positive_train = []\n",
        "false_positive_train = []\n",
        "false_negative_train = []\n",
        "iou_train = []\n",
        "true_positive_val = []\n",
        "false_positive_val = []\n",
        "false_negative_val = []\n",
        "iou_val = []\n",
        "thresh = [-0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]\n",
        "for i in thresh:\n",
        "    y_train_pred_bin = np.round(y_train_pred + i, 0)\n",
        "    y_val_pred_bin = np.round(y_val_pred + i, 0)\n",
        "    conf_train = confusion_matrix(y_train_pred_bin, y_train)\n",
        "    true_positive_train.append(conf_train[1,1])\n",
        "    false_positive_train.append(conf_train[1,0])\n",
        "    false_negative_train.append(conf_train[0,1])\n",
        "    iou_train.append(conf_train[1,1]/(conf_train[1,1]+conf_train[1,0]+conf_train[0,1]))\n",
        "    conf_val = confusion_matrix(y_val_pred_bin, y_val)\n",
        "    true_positive_val.append(conf_val[1,1])\n",
        "    false_positive_val.append(conf_val[1,0])\n",
        "    false_negative_val.append(conf_val[0,1])\n",
        "    iou_val.append(conf_val[1,1]/(conf_val[1,1]+conf_val[1,0]+conf_val[0,1]))\n",
        "d = {'true_positive_train': true_positive_train, 'false_positive_train':  \\\n",
        "     false_positive_train, 'false_negative_train': false_negative_train, \\\n",
        "     'iou_train': iou_train, 'true_positive_val': true_positive_val, 'false_positive_val':  \\\n",
        "     false_positive_val, 'false_negative_val': false_negative_val, 'iou_val': iou_val, }\n",
        "df = pd.DataFrame.from_dict(d, orient='index')\n",
        "df.columns = ['-0.1', '-0.05', '0', '0.05', '0.1', '0.15', '0.2', '0.25', '0.3', '0.35']\n",
        "plt.plot(thresh, iou_train) \n",
        "plt.plot(thresh, iou_val)\n",
        "plt.legend(['train', 'val'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "i = 0.05 # <- lower threshold for positive predictions (i.e: i=0.1 --> threshold=0.4)\n",
        "y_train_pred_bin = np.round(y_train_pred + i, 0)\n",
        "y_val_pred_bin = np.round(y_val_pred + i, 0)\n",
        "loss_train = log_loss(y_train, y_train_pred)\n",
        "loss_val = log_loss(y_val, y_val_pred)               \n",
        "print('mean IOU training: ' + str(iou_train[3]))\n",
        "print('mean IOU validation: ' + str(iou_val[3]))\n",
        "print('loss training: ' + str(loss_train))\n",
        "print('loss validation: ' + str(loss_val))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFOCAYAAAC8HtVyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f8c65f76588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean IOU training: 0.8470229981309897\n",
            "mean IOU validation: 0.76159119072345\n",
            "loss training: nan\n",
            "loss validation: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7zEtiGBecib4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###### Download results to local computer for evaluation [NOT IN USE]\n",
        "# from google.colab import files\n",
        "# results_train = pd.DataFrame({'y_train': y_train.reshape(-1)[:(400*101*101)],'y_train_pred': \\\n",
        "#                               y_train_pred.reshape(-1)[:(400*101*101)]})\n",
        "# results_train.to_csv(\"results_train.csv\")\n",
        "# results_val = pd.DataFrame({'y_val': y_val.reshape(-1),'y_val_pred': y_val_pred.reshape(-1)})\n",
        "# results_val.to_csv('results_val.csv')\n",
        "# files.download('results_train.csv')\n",
        "# files.download('results_val.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KUyxv0dEuESf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c690fee6-2499-4c05-9894-4d62bcde3461"
      },
      "cell_type": "code",
      "source": [
        "y_val_pred.mean()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23033868"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "0utIsbRcdSfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c1cc49a-3e24-48d7-e148-62f1bf540900"
      },
      "cell_type": "code",
      "source": [
        "##### save model and weights\n",
        "# https://stackoverflow.com/questions/48924165/google-colaboratory-weight-download-export-saved-models\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "# 2. Save Keras Model or weights on google drive\n",
        "# create on Colab directory\n",
        "model.save('model_3322.h5')    \n",
        "model_file = drive.CreateFile({'title' : 'model_3322.h5'})\n",
        "model_file.SetContentFile('model_3322.h5')\n",
        "model_file.Upload()\n",
        "drive.CreateFile({'id': model_file.get('id')})\n",
        "model.save_weights('model_weights_3322.h5')\n",
        "weights_file = drive.CreateFile({'title' : 'model_weights_3322.h5'})\n",
        "weights_file.SetContentFile('model_weights_3322.h5')\n",
        "weights_file.Upload()\n",
        "drive.CreateFile({'id': weights_file.get('id')})"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '12cqpOyyqEEl30jGmcjEVoARfDcB9bicC'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "kr3Gx7H6CpC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "accbba9e-931e-48d9-e03e-c975b65ff9c0"
      },
      "cell_type": "code",
      "source": [
        "y_train_pred[50:100]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00503684, 0.00538168, 0.00586951, 0.00647025, 0.00719448,\n",
              "       0.0079073 , 0.00856224, 0.0091567 , 0.00967239, 0.01021167,\n",
              "       0.01074237, 0.0112762 , 0.01181257, 0.01234576, 0.01286832,\n",
              "       0.01336894, 0.01377307, 0.01406397, 0.01426635, 0.01450133,\n",
              "       0.01483444, 0.01526764, 0.01578286, 0.01636514, 0.01702736,\n",
              "       0.01774496, 0.01859898, 0.01970528, 0.02104622, 0.02275222,\n",
              "       0.02472558, 0.02707887, 0.02984645, 0.03322568, 0.03719867,\n",
              "       0.04203765, 0.04655034, 0.05003434, 0.05184649, 0.05240975,\n",
              "       0.05280109, 0.05290642, 0.05327027, 0.05395169, 0.05453774,\n",
              "       0.05469927, 0.05456806, 0.05541839, 0.05564683, 0.05594668],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}