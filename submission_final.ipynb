{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "submission_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/roman807/TGS_Salt/blob/master/submission_final.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "hO7PM-XEPCBr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import confusion_matrix, log_loss\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "import h5py\n",
        "import csv "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qamtuYPhPJti",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ------------------- Load data (use kaggle API) ------------------- #\n",
        "!pip install kaggle\n",
        "api_token = {\"username\":\"######\",\"key\":\"############################\"}\n",
        "os.chdir('/')\n",
        "!mkdir ~/.kaggle #kaggle API searches in root directory for .kaggle/kaggle.jso\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "# API link from Kaggle:\n",
        "!kaggle competitions download -c tgs-salt-identification-challenge\n",
        "zip_ref = zipfile.ZipFile('test.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_U9K4-4qPMiT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ------------------- Prepare data ------------------- #\n",
        "t_image_dir = os.chdir('/images')\n",
        "test_im = os.listdir(t_image_dir)\n",
        "x = np.array([np.array(cv2.imread(p, cv2.IMREAD_GRAYSCALE)) for p in test_im]) / 255\n",
        "x = np.expand_dims(x, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4JSIPr_SAJ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ------------------- Authorize connection to google drive ------------------- #\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3ObR10BSGnX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ------------------- Load model from Google drive ------------------- #\n",
        "last_model_file = drive.CreateFile({'id': '##############################'}) \n",
        "last_model_file.GetContentFile('model_3322rn.hdf5')\n",
        "new_model = models.load_model('model_3322rn.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oRnshQANSO9h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ------------------- Predict results ------------------- #\n",
        "y_pred = new_model.predict(x, verbose=1)\n",
        "y_pred_bin = np.round(y_pred + 0.0, 0) # <-- change threshold if necessary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ctF1rMKTGK3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ------------------- Create string for submission ------------------- #\n",
        "final_string = []\n",
        "for element in y_pred_bin:\n",
        "  locations = []\n",
        "  counters = []\n",
        "  loc_count = []\n",
        "  array = np.transpose(element).flatten()\n",
        "  if array[0]==1:\n",
        "    locations.append(1)\n",
        "    counters.append(1)\n",
        "  for i in range(1,len(array)):\n",
        "    if array[i] == 1:\n",
        "      if array[i-1] == 0:\n",
        "        locations.append(i+1)\n",
        "        counters.append(1)\n",
        "      else:\n",
        "        counters[-1] += 1   \n",
        "  for i in range(len(locations)):\n",
        "    loc_count.append(locations[i])\n",
        "    loc_count.append(counters[i])\n",
        "  string = ' '.join(str(l) for l in loc_count)    \n",
        "  final_string.append(string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kLUTdafub6Sw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ------------------- Download submission file ------------------- #\n",
        "names = [word.split('.')[0] for word in test_im]\n",
        "with open('submission_rn2.csv', 'w', newline ='') as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  writer.writerow(['id', 'rle_mask'])\n",
        "  for i in range(len(names)):\n",
        "    writer.writerow([names[i], final_string[i]])\n",
        "files.download('submission_rn2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PUllMs0FBc4z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ------------------- Save to google drive ------------------- #\n",
        "uploaded = drive.CreateFile({'title': 'submission_rn2.csv'})\n",
        "uploaded.SetContentFile('submission_rn2.csv')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}