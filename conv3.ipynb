{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Romanm87/TGS_Salt/blob/master/conv3.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "10jLll6VKy4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "07330ec8-585b-4890-bf6c-ab24d9c4e74a"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.layers import Input, Conv2D\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import zipfile"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jcxbq-qBLEaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "0da24e81-edd2-4ccd-838a-07b00feafd3e"
      },
      "cell_type": "code",
      "source": [
        "# Use kaggle API\n",
        "\n",
        "!pip install kaggle\n",
        "api_token = {\"username\":\"romanm87\",\"key\":\"###################\"}\n",
        "\n",
        "os.chdir('/')\n",
        "!mkdir ~/.kaggle #kaggle API searches in root directory for .kaggle/kaggle.json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# API link from Kaggle:\n",
        "!kaggle competitions download -c tgs-salt-identification-challenge\n",
        "\n",
        "zip_ref = zipfile.ZipFile('train.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/78/832b9a9ec6b3baf8ec566e1f0a695f2fd08d2c94a6797257a106304bfc3c/kaggle-1.4.7.1.tar.gz (52kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.8.24)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.26.0)\n",
            "Collecting python-slugify (from kaggle)\n",
            "  Downloading https://files.pythonhosted.org/packages/00/ad/c778a6df614b6217c30fe80045b365bfa08b5dd3cb02e8b37a6d25126781/python-slugify-1.2.6.tar.gz\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Collecting Unidecode>=0.04.16 (from python-slugify->kaggle)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/ef/67085e30e8bbcdd76e2f0a4ad8151c13a2c5bce77c85f8cad6e1f16fb141/Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n",
            "\u001b[K    100% |████████████████████████████████| 235kB 7.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
            "  Running setup.py bdist_wheel for kaggle ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/44/2c/df/22a6eeb780c36c28190faef6252b739fdc47145fd87a6642d4\n",
            "  Running setup.py bdist_wheel for python-slugify ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e3/65/da/2045deea3098ed7471eca0e2460cfbd3fdfe8c1d6fa6fcac92\n",
            "Successfully built kaggle python-slugify\n",
            "Installing collected packages: Unidecode, python-slugify, kaggle\n",
            "Successfully installed Unidecode-1.0.22 kaggle-1.4.7.1 python-slugify-1.2.6\n",
            "Downloading depths.csv to /\n",
            "  0% 0.00/322k [00:00<?, ?B/s]\n",
            "100% 322k/322k [00:00<00:00, 72.0MB/s]\n",
            "Downloading sample_submission.csv to /\n",
            "  0% 0.00/264k [00:00<?, ?B/s]\n",
            "100% 264k/264k [00:00<00:00, 71.4MB/s]\n",
            "Downloading train.csv to /\n",
            "  0% 0.00/922k [00:00<?, ?B/s]\n",
            "100% 922k/922k [00:00<00:00, 83.1MB/s]\n",
            "Downloading test.zip to /\n",
            " 91% 148M/163M [00:01<00:00, 93.0MB/s]\n",
            "100% 163M/163M [00:01<00:00, 98.3MB/s]\n",
            "Downloading train.zip to /\n",
            " 53% 20.0M/37.9M [00:00<00:00, 40.4MB/s]\n",
            "100% 37.9M/37.9M [00:00<00:00, 112MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0lxZRT5eLUm7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Prepare data and model\n",
        "tr_image_dir = os.chdir('/images')\n",
        "train_im = os.listdir(tr_image_dir)\n",
        "x = np.array([np.array(cv2.imread(p, cv2.IMREAD_GRAYSCALE)) for p in train_im]) / 255\n",
        "\n",
        "tr_masks_dir = os.chdir('/masks')\n",
        "train_ma = os.listdir(tr_masks_dir)\n",
        "y = np.array([np.array(cv2.imread(p, cv2.IMREAD_GRAYSCALE)) for p in train_ma]) / 255\n",
        "\n",
        "# expand dimensions for CNN inout\n",
        "x = np.expand_dims(x, axis=3)\n",
        "y = np.expand_dims(y, axis=3)\n",
        "\n",
        "# split training vs validation set\n",
        "train_val_split = 0.1\n",
        "x_train = x[0:int(x.shape[0]*(1-train_val_split)),:,:,:]\n",
        "y_train = y[0:int(y.shape[0]*(1-train_val_split)),:,:,:]\n",
        "x_val = x[int(x.shape[0]*(1-train_val_split)):,:,:,:]\n",
        "y_val = y[int(y.shape[0]*(1-train_val_split)):,:,:,:]\n",
        "\n",
        "def conv_block(x_input, num_layers, f, k):\n",
        "    x = x_input\n",
        "    for l in range(num_layers):\n",
        "        x = Conv2D(f, (k, k), padding = 'SAME', activation = 'relu')(x)\n",
        "    return x\n",
        "\n",
        "def conv_net(input_shape, num_layers, num_filters, kernel_sizes):\n",
        "    x_input = Input(input_shape)\n",
        "    x = conv_block(x_input, num_layers[0], num_filters[0], kernel_sizes[0])\n",
        "    x = conv_block(x, num_layers[1], num_filters[1], kernel_sizes[1])\n",
        "    x = conv_block(x, num_layers[2], num_filters[2], kernel_sizes[2])\n",
        "    x = conv_block(x, num_layers[3], num_filters[3], kernel_sizes[3])\n",
        "    x = conv_block(x, num_layers[4], num_filters[4], kernel_sizes[4])\n",
        "    x = Conv2D(1, (1,1), activation = 'sigmoid')(x)\n",
        "    model = Model(inputs = x_input, outputs=x)\n",
        "    return model\n",
        "\n",
        "#input_shape = Input(shape = (101,101,1))\n",
        "input_shape = (101, 101, 1)\n",
        "num_layers = [1, 1, 1, 1, 1] #[5, 5, 5, 5, 5]\n",
        "num_filters = [16, 8, 8, 4, 2] #[32, 24, 16, 8, 4]\n",
        "kernel_sizes = [3, 5, 7, 9, 11]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g1rD4XqXTL1H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Define \n",
        "\n",
        "class MeanIoU(object):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def mean_iou(self, y_true, y_pred):\n",
        "        # Wraps np_mean_iou method and uses it as a TensorFlow op.\n",
        "        # Takes numpy arrays as its arguments and returns numpy arrays as outputs\n",
        "        return tf.py_func(self.np_mean_iou, [y_true, y_pred], tf.float64)\n",
        "    def np_mean_iou(self, y_true, y_pred):\n",
        "        y_pred = np.round(y_pred + 0.05, 0).reshape(-1)\n",
        "        y_true = y_true.reshape(-1)        \n",
        "        conf = confusion_matrix(y_pred, y_true)        \n",
        "        # Compute the IoU and mean IoU from the confusion matrix:\n",
        "        true_positive = conf[1,1]\n",
        "        false_positive = conf[1,0]\n",
        "        false_negative = conf[0,1]\n",
        "        # Just in case we get a division by 0, ignore/hide the error and set the value to 0\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            iou = true_positive / (true_positive + false_positive + false_negative)\n",
        "        #iou[np.isnan(iou)] = 0\n",
        "        return np.mean(iou).astype(np.float64)\n",
        "miou = MeanIoU()\n",
        "\n",
        "def bin_acc05(y_true, y_pred):\n",
        "    return K.mean(K.equal(y_true, K.round(y_pred + 0.05)), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2YS5nw4TdaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "e91ea663-dcbc-4208-ab96-37ff20e8a0e7"
      },
      "cell_type": "code",
      "source": [
        "##### Define model \n",
        "model = conv_net(input_shape, num_layers, num_filters, kernel_sizes)\n",
        "adam = optimizers.Adam(lr = 0.001)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam', \n",
        "              metrics=[bin_acc05, miou.mean_iou])\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 101, 101, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 101, 101, 16)      160       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 101, 101, 8)       3208      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 101, 101, 8)       3144      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 101, 101, 4)       2596      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 101, 101, 2)       970       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 101, 101, 1)       3         \n",
            "=================================================================\n",
            "Total params: 10,081\n",
            "Trainable params: 10,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "14N0XizsTie-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a2333f66-e980-417c-fcbd-a225cae5c10c"
      },
      "cell_type": "code",
      "source": [
        "##### Run model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_data=(x_val,y_val), verbose=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3600 samples, validate on 400 samples\n",
            "Epoch 1/5\n",
            "3600/3600 [==============================] - 39s 11ms/step - loss: 0.6901 - bin_acc05: 0.2453 - mean_iou: 0.2453 - val_loss: 0.6869 - val_bin_acc05: 0.2717 - val_mean_iou: 0.2717\n",
            "Epoch 2/5\n",
            "3600/3600 [==============================] - 35s 10ms/step - loss: 0.6829 - bin_acc05: 0.2453 - mean_iou: 0.2453 - val_loss: 0.6807 - val_bin_acc05: 0.2717 - val_mean_iou: 0.2717\n",
            "Epoch 3/5\n",
            "3600/3600 [==============================] - 35s 10ms/step - loss: 0.6761 - bin_acc05: 0.2453 - mean_iou: 0.2453 - val_loss: 0.6747 - val_bin_acc05: 0.2717 - val_mean_iou: 0.2717\n",
            "Epoch 4/5\n",
            "3600/3600 [==============================] - 34s 10ms/step - loss: 0.6695 - bin_acc05: 0.2453 - mean_iou: 0.2453 - val_loss: 0.6692 - val_bin_acc05: 0.2717 - val_mean_iou: 0.2717\n",
            "Epoch 5/5\n",
            "3600/3600 [==============================] - 34s 10ms/step - loss: 0.6632 - bin_acc05: 0.2453 - mean_iou: 0.2453 - val_loss: 0.6637 - val_bin_acc05: 0.2717 - val_mean_iou: 0.2717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2082b338d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "JYSRYTCSZxST",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Predict results\n",
        "y_train_pred = model.predict(x_train, verbose=1)\n",
        "y_val_pred = model.predict(x_val, verbose=1)\n",
        "\n",
        "# evaluate on local computer\n",
        "#true_positive_train = []\n",
        "#false_positive_train = []\n",
        "#false_negative_train = []\n",
        "#true_positive_val = []\n",
        "#false_positive_val = []\n",
        "#false_negative_val = []\n",
        "#thresh = [0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]\n",
        "#for i in thresh:\n",
        "#    y_train_pred_bin = np.round(y_train_pred + i, 0)\n",
        "#    y_val_pred_bin = np.round(y_val_pred + i, 0)\n",
        "#    conf_train = confusion_matrix(list(y_train_pred_bin.reshape(-1)), list(y_train.reshape(-1)))\n",
        "#    true_positive_train.append(conf_train[1,1])\n",
        "#    false_positive_train.append(conf_train[1,0])\n",
        "#    false_negative_train.append(conf_train[0,1])\n",
        "#    iou_train.append(conf_train[1,1]/(conf_train[1,1]+conf_train[1,0]+conf_train[0,1]))\n",
        "#    conf_val = confusion_matrix(list(y_val_pred_bin.reshape(-1)), list(y_val.reshape(-1)))\n",
        "#    true_positive_val.append(conf_val[1,1])\n",
        "#    false_positive_val.append(conf_val[1,0])\n",
        "#    false_negative_val.append(conf_val[0,1])\n",
        "#    iou_val.append(conf_val[1,1]/(conf_val[1,1]+conf_val[1,0]+conf_val[0,1]))\n",
        "\n",
        "#print('true pos train', true_positive_train)\n",
        "#print('false pos train', false_positive_train)\n",
        "#print('false neg train', false_negative_train)\n",
        "#print('true pos val', true_positive_val)\n",
        "#print('false pos val', false_positive_val)\n",
        "#print('false neg val', false_negative_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FimHL-Liama-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###### Download results to local computer for evaluation\n",
        "from google.colab import files\n",
        "results_train = pd.DataFrame({'y_train': y_train.reshape(-1),'y_train_pred': y_train_pred.reshape(-1)})\n",
        "results_train.to_csv(\"results_train.csv\")\n",
        "results_val = pd.DataFrame({'y_val': y_val.reshape(-1),'y_val_pred': y_val_pred.reshape(-1)})\n",
        "results_val.to_csv(\"results_val.csv\")\n",
        "files.download('results_train.csv')\n",
        "files.download('results_val.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
